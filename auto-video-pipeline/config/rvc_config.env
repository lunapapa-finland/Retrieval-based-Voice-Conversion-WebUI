# ========= COMMON CONFIG =========
EXP="Formal"                              # Experiment name (used in both training and inference)

# ========= TRAINING CONFIG =========
DATA_DIR="./data/myvoice"               # raw audio folder
SR="40k"                                # 32k/40k/48k
SAMPLE_RATE_HZ=40000                    # 32000/40000/48000
NPROC=7                                 # workers (set 0 to auto-detect CPU cores)
VERSION="v2"                            # v1 or v2
FEAT_DIM=768                            # v2=768, v1 often 256
BATCH_SIZE=1
TOTAL_EPOCH=150
SAVE_EVERY=10
PRETRAIN_G="assets/pretrained_v2/f0G40k.pth"
PRETRAIN_D="assets/pretrained_v2/f0D40k.pth"

# Device used for feature extraction (HuBERT): mps | cuda | cpu
# Tip: use 'mps' on Apple Silicon/macOS, 'cuda' on NVIDIA/Linux, 'cpu' as a fallback.
DEVICE="mps"

# Optional: train FAISS index after feature/F0
TRAIN_INDEX=1                           # 0 to skip
KMEANS=0                                # e.g. 10000 to enable downsampling

# ========= INFERENCE CONFIG =========
INPUT_DIR="auto-video-pipeline/data/step2_wav-tts"       # Input folder with .wav files
RESULT_DIR="auto-video-pipeline/data/step3_wav-converted"             # Output folder
CHECKPOINT="Formal_e130_s58890.pth"
F0_METHOD="rmvpe"                       # Pitch extraction method
RMS_MIX_RATE="0.25"                     # RMS mix rate
PROTECT="0.33"                          # Protect unvoiced consonants
FILTER_RADIUS="3"                       # Pitch filter radius
